{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5082681,"sourceType":"datasetVersion","datasetId":2951364}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Local IDS Using LSTM (BoT-IoT Dataset)****","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport os\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Ensure TensorFlow Uses GPU (If Available)\nprint(\"Checking GPU availability...\")\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\nif physical_devices:\n    try:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n        print(f\"GPU Available: {physical_devices[0]}\")\n    except RuntimeError as e:\n        print(f\"GPU Memory Growth Could Not Be Set: {e}\")\nelse:\n    print(\"No GPU found. Running on CPU.\")\n\n# ------------------------------------\n# Load & Preprocess the BoT-IoT Dataset\n# ------------------------------------\n\n# Path to dataset folder\ndataset_folder = \"/kaggle/input/bot-iot\"\n\n# List all CSV files in the folder\nfile_paths = [os.path.join(dataset_folder, file) for file in os.listdir(dataset_folder) if file.endswith(\".csv\")]\n\n# Load and combine all BoT-IoT datasets\nall_dfs = []\nfor file in file_paths:\n    df = pd.read_csv(file)\n    df[\"Dataset\"] = file  # Track dataset source\n    all_dfs.append(df)\n\n# Merge all datasets\nbot_iot_df = pd.concat(all_dfs, ignore_index=True)\n\n# Standardize column names\nbot_iot_df.columns = bot_iot_df.columns.str.strip().str.replace(' ', '_').str.replace('/', '_')\n\n# Print available columns\nprint(\"Available Columns:\", bot_iot_df.columns.tolist())\n\n# Define Correct Feature List\nselected_features = [\n    \"Flow_Duration\", \"Tot_Fwd_Pkts\", \"Tot_Bwd_Pkts\", \"Fwd_Pkt_Len_Mean\",\n    \"Bwd_Pkt_Len_Mean\", \"Flow_Byts_s\", \"Flow_Pkts_s\", \"Bwd_Pkts_s\",\n    \"Bwd_Pkt_Len_Max\", \"SDN_Priority\"\n]\n\n# Check for missing columns before processing\nmissing_cols = [col for col in selected_features if col not in bot_iot_df.columns]\nif missing_cols:\n    raise ValueError(f\"Missing Columns: {missing_cols}. Update 'selected_features' list to match dataset.\")\n\n# Encode Labels\nlabel_encoder = LabelEncoder()\nbot_iot_df[\"Label\"] = label_encoder.fit_transform(bot_iot_df[\"Label\"])\n\n# Standardize numeric features\nscaler = StandardScaler()\nX = scaler.fit_transform(bot_iot_df[selected_features])\ny = tf.keras.utils.to_categorical(bot_iot_df[\"Label\"])  # One-hot encode labels\n\n# Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reshape inputs to be 3D for LSTM (batch_size, time_steps=1, features)\nX_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nX_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n\n# ------------------------------------\n# Build the LSTM-Based Local IDS Model\n# ------------------------------------\n\nlstm_model = Sequential([\n    LSTM(64, return_sequences=True, input_shape=(1, X.shape[1])),\n    Dropout(0.2),\n    BatchNormalization(),\n\n    LSTM(32, return_sequences=False),\n    Dropout(0.2),\n    BatchNormalization(),\n\n    Dense(64, activation=\"relu\"),\n    Dropout(0.3),\n    Dense(y.shape[1], activation=\"softmax\")  # Multi-class classification\n])\n\n# Compile Model\nlstm_model.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# ------------------------------------\n# Train the Model (Using GPU Acceleration)\n# ------------------------------------\nprint(\"Training LSTM-Based Local IDS...\")\nhistory = lstm_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25, batch_size=32)\n\n# ------------------------------------\n# Evaluate & Compare with Paperâ€™s Results\n# ------------------------------------\n# Predict on test data\ny_pred = np.argmax(lstm_model.predict(X_test), axis=1)\ny_true = np.argmax(y_test, axis=1)\n\n# Print Accuracy & Classification Report\naccuracy = accuracy_score(y_true, y_pred)\nprint(f\"Local IDS Model Accuracy: {accuracy * 100:.2f}%\")\nprint(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n\n# Confusion Matrix\nplt.figure(figsize=(8, 6))\ncm = confusion_matrix(y_true, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix - Local IDS LSTM Model\")\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}